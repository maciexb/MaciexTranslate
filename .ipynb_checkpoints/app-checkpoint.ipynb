{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with windowsapi reloader\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Instalki\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries and functions\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import json\n",
    "#model = load_model(\"s2s.h5\", compile=False)\n",
    "\n",
    "max_len_input_final = 50\n",
    "max_len_target_final = 30\n",
    "\n",
    "app = Flask(__name__) #Initialize the flask App\n",
    "path = r\"D:\\Dokumenty\\DeepNLP\\machine_learning_examples\\nlp_class3\\OwnScripts\\Flask\\model_spec\"\n",
    "\n",
    "encoder_model = load_model(path +\"\\\\encoder_model.h5\", compile=False)\n",
    "decoder_model = load_model(path +\"\\\\decoder_model.h5\", compile=False)\n",
    "\n",
    "with open(path + \"\\\\word2idx_inputs.txt\") as file:\n",
    "    word2idx_inputs = json.loads(file.read())\n",
    "\n",
    "with open(path + \"\\\\word2idx_outputs.txt\") as file:\n",
    "    word2idx_outputs = json.loads(file.read())\n",
    "\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "\n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target_final):\n",
    "    output_tokens, h, c = decoder_model.predict(\n",
    "      [target_seq] + states_value\n",
    "    )\n",
    "    # output_tokens, h = decoder_model.predict(\n",
    "    #     [target_seq] + states_value\n",
    "    # ) # gru\n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "    # Update states\n",
    "    states_value = [h, c]\n",
    "    # states_value = [h] # gru\n",
    "\n",
    "  return ' '.join(output_sentence)\n",
    "\n",
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( word2idx_inputs[ word ] ) \n",
    "    return pad_sequences( [tokens_list] , maxlen=max_len_input_final)\n",
    "\n",
    "@app.route('/') # Homepage\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "    '''\n",
    "    For rendering results on HTML GUI\n",
    "    '''\n",
    "    input_seq = str_to_tokens(request.form)\n",
    "    translation = decode_sequence(input_seq)\n",
    "    #print('-')\n",
    "    #print('Input:', input_texts[i])\n",
    "    print('Translation:', translation)\n",
    "\n",
    "    return render_template('index.html', prediction_text='Predicted Class: {}'.format(translation)) # rendering the predicted result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
